{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tables\n",
    "\n",
    "from tables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will learn how to browse the tree and retrieve data and also meta-information about the actual data.\n",
    "In examples/tutorial1-2.py you will find the working version of all the code in this section. As before, you are encouraged to use a python shell and inspect the object tree during the course of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traversing the object tree\n",
    "Let’s start by opening the file we created in last tutorial section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file = open_file(\"tmp/tutorial1.h5\", \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we have opened the file in “a”ppend mode. We use this mode to add more information to the file.\n",
    "PyTables, following the Python tradition, offers powerful introspection capabilities, i.e. you can easily ask information about any component of the object tree as well as search the tree.\n",
    "To start with, you can get a preliminary overview of the object tree by simply printing the existing File instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/tutorial1.h5 (File) 'Test file'\n",
      "Last modif.: 'Mon Sep 23 12:52:43 2019'\n",
      "Object Tree: \n",
      "/ (RootGroup) 'Test file'\n",
      "/columns (Group) 'Pressure and Name'\n",
      "/columns/name (Array(3,)) 'Name column selection'\n",
      "/columns/pressure (Array(3,)) 'Pressure column selection'\n",
      "/detector (Group) 'Detector information'\n",
      "/detector/readout (Table(10,)) 'Readout example'\n",
      "/gabes_group (Group) 'gabes random group'\n",
      "/gabes_group/gabes_table (Table(0,)) 'Gabe Table Example'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) 'Test file'\n",
      "/columns (Group) 'Pressure and Name'\n",
      "/detector (Group) 'Detector information'\n",
      "/gabes_group (Group) 'gabes random group'\n",
      "/columns/name (Array(3,)) 'Name column selection'\n",
      "/columns/pressure (Array(3,)) 'Pressure column selection'\n",
      "/detector/readout (Table(10,)) 'Readout example'\n",
      "/gabes_group/gabes_table (Table(0,)) 'Gabe Table Example'\n"
     ]
    }
   ],
   "source": [
    "# It looks like all of our objects are there. Now let’s make use of the File \n",
    "# iterator to see how to list all the nodes in the object tree:\n",
    "for node in h5file:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) 'Test file'\n",
      "/columns (Group) 'Pressure and Name'\n",
      "/detector (Group) 'Detector information'\n",
      "/gabes_group (Group) 'gabes random group'\n"
     ]
    }
   ],
   "source": [
    "# We can use the File.walk_groups() method of the File class to list only the groups on tree:\n",
    "for group in h5file.walk_groups():\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/columns/name (Array(3,)) 'Name column selection'\n",
      "/columns/pressure (Array(3,)) 'Pressure column selection'\n"
     ]
    }
   ],
   "source": [
    "# Note that File.walk_groups() actually returns an iterator, not a list of objects. \n",
    "# Using this iterator with the list_nodes() method is a powerful combination. \n",
    "# Let’s see an example listing of all the arrays in the tree:\n",
    "for group in h5file.walk_groups(\"/\"):\n",
    "    for array in h5file.list_nodes(group, classname='Array'):\n",
    "        print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`File.list_nodes()` returns a list containing all the nodes hanging off a specific Group. If the classname keyword is specified, the method will filter out all instances which are not descendants of the class. We have asked for only Array instances. There exist also an iterator counterpart called File.iter_nodes() that might be handy is some situations, like for example when dealing with groups with a large number of nodes behind it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/columns/name (Array(3,)) 'Name column selection'\n",
      "/columns/pressure (Array(3,)) 'Pressure column selection'\n"
     ]
    }
   ],
   "source": [
    "# We can combine both calls by using the File.walk_nodes() special method of the File object. For example:\n",
    "for array in h5file.walk_nodes(\"/\", \"Array\"):\n",
    "    print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used a call to the `Group._f_walknodes()` method, using the natural naming path specification.\n",
    "Of course you can do more sophisticated node selections using these powerful methods. But first, let’s take a look at some important PyTables object instance variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting and getting user attributes\n",
    "PyTables provides an easy and concise way to complement the meaning of your node objects on the tree by using the AttributeSet class (see The AttributeSet class). You can access this object through the standard attribute attrs in Leaf nodes and _v_attrs in Group nodes.\n",
    "\n",
    "For example, let’s imagine that we want to save the date indicating when the data in /detector/readout table has been acquired, as well as the temperature during the gathering process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = h5file.root.detector.readout\n",
    "table.attrs.gath_date = \"Wed, 06/12/2003 18:33\"\n",
    "table.attrs.temperature = 18.4\n",
    "table.attrs.temp_scale = \"Celsius\"\n",
    "table.attrs.is_gaby_the_best = 'Hell yeah he is!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/detector/readout._v_attrs (AttributeSet), 25 attributes:\n",
       "   [CLASS := 'TABLE',\n",
       "    FIELD_0_FILL := 0,\n",
       "    FIELD_0_NAME := 'ADCcount',\n",
       "    FIELD_1_FILL := 0,\n",
       "    FIELD_1_NAME := 'TDCcount',\n",
       "    FIELD_2_FILL := 0.0,\n",
       "    FIELD_2_NAME := 'energy',\n",
       "    FIELD_3_FILL := 0,\n",
       "    FIELD_3_NAME := 'grid_i',\n",
       "    FIELD_4_FILL := 0,\n",
       "    FIELD_4_NAME := 'grid_j',\n",
       "    FIELD_5_FILL := 0,\n",
       "    FIELD_5_NAME := 'idnumber',\n",
       "    FIELD_6_FILL := b'',\n",
       "    FIELD_6_NAME := 'name',\n",
       "    FIELD_7_FILL := 0.0,\n",
       "    FIELD_7_NAME := 'pressure',\n",
       "    NROWS := 10,\n",
       "    TITLE := 'Readout example',\n",
       "    VERSION := '2.7',\n",
       "    gath_date := 'Wed, 06/12/2003 18:33',\n",
       "    is_gaby_the_best := 'Hell yeah he is!',\n",
       "    tempScale := 'Celsius',\n",
       "    temp_scale := 'Celsius',\n",
       "    temperature := 18.4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let’s set a somewhat more complex attribute in the /detector group:\n",
    "detector = h5file.root.detector\n",
    "detector._v_attrs.stuff = [5, (2.3, 4.5), \"Integer and tuple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/detector._v_attrs (AttributeSet), 4 attributes:\n",
       "   [CLASS := 'GROUP',\n",
       "    TITLE := 'Detector information',\n",
       "    VERSION := '1.0',\n",
       "    stuff := [5, (2.3, 4.5), 'Integer and tuple']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector._v_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the AttributeSet instance is accessed with the _v_attrs attribute because detector is a Group node. In general, you can save any standard Python data structure as an attribute node. See The AttributeSet class for a more detailed explanation of how they are serialized for export to disk.\n",
    "\n",
    "Retrieving the attributes is equally simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table.attrs.gath_date := Wed, 06/12/2003 18:33\n",
      "table.attrs.temperature := 18.4\n",
      "table.attrs.temp_scale := Celsius\n",
      "detector._v_attrs.stuff := [5, (2.3, 4.5), 'Integer and tuple']\n"
     ]
    }
   ],
   "source": [
    "print('table.attrs.gath_date := %s' % table.attrs.gath_date)\n",
    "print('table.attrs.temperature := %s' % table.attrs.temperature)\n",
    "print('table.attrs.temp_scale := %s' % table.attrs.temp_scale)\n",
    "print('detector._v_attrs.stuff := %s' % detector._v_attrs.stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can probably guess how to delete attributes:\n",
    "del table.attrs.gath_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to examine the current user attribute set of /detector/table, you can print its representation (try hitting the TAB key twice if you are on a Unix Python console with the rlcompleter module active):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/detector/readout._v_attrs (AttributeSet), 24 attributes:\n",
       "   [CLASS := 'TABLE',\n",
       "    FIELD_0_FILL := 0,\n",
       "    FIELD_0_NAME := 'ADCcount',\n",
       "    FIELD_1_FILL := 0,\n",
       "    FIELD_1_NAME := 'TDCcount',\n",
       "    FIELD_2_FILL := 0.0,\n",
       "    FIELD_2_NAME := 'energy',\n",
       "    FIELD_3_FILL := 0,\n",
       "    FIELD_3_NAME := 'grid_i',\n",
       "    FIELD_4_FILL := 0,\n",
       "    FIELD_4_NAME := 'grid_j',\n",
       "    FIELD_5_FILL := 0,\n",
       "    FIELD_5_NAME := 'idnumber',\n",
       "    FIELD_6_FILL := b'',\n",
       "    FIELD_6_NAME := 'name',\n",
       "    FIELD_7_FILL := 0.0,\n",
       "    FIELD_7_NAME := 'pressure',\n",
       "    NROWS := 10,\n",
       "    TITLE := 'Readout example',\n",
       "    VERSION := '2.7',\n",
       "    is_gaby_the_best := 'Hell yeah he is!',\n",
       "    tempScale := 'Celsius',\n",
       "    temp_scale := 'Celsius',\n",
       "    temperature := 18.4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve got all the attributes (including the system attributes). You can get a list of all attributes or only the user or system attributes with the `_f_list()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLASS', 'FIELD_0_FILL', 'FIELD_0_NAME', 'FIELD_1_FILL', 'FIELD_1_NAME', 'FIELD_2_FILL', 'FIELD_2_NAME', 'FIELD_3_FILL', 'FIELD_3_NAME', 'FIELD_4_FILL', 'FIELD_4_NAME', 'FIELD_5_FILL', 'FIELD_5_NAME', 'FIELD_6_FILL', 'FIELD_6_NAME', 'FIELD_7_FILL', 'FIELD_7_NAME', 'NROWS', 'TITLE', 'VERSION', 'is_gaby_the_best', 'tempScale', 'temp_scale', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "print(table.attrs._f_list(\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_gaby_the_best', 'tempScale', 'temp_scale', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "print(table.attrs._f_list(\"user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CLASS', 'FIELD_0_FILL', 'FIELD_0_NAME', 'FIELD_1_FILL', 'FIELD_1_NAME', 'FIELD_2_FILL', 'FIELD_2_NAME', 'FIELD_3_FILL', 'FIELD_3_NAME', 'FIELD_4_FILL', 'FIELD_4_NAME', 'FIELD_5_FILL', 'FIELD_5_NAME', 'FIELD_6_FILL', 'FIELD_6_NAME', 'FIELD_7_FILL', 'FIELD_7_NAME', 'NROWS', 'TITLE', 'VERSION']\n"
     ]
    }
   ],
   "source": [
    "print(table.attrs._f_list(\"sys\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is_gaby_the_best', 'tempScale', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "# You can also rename attributes:\n",
    "table.attrs._f_rename(\"temp_scale\",\"tempScale\")\n",
    "print(table.attrs._f_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And, from PyTables 2.0 on, you are allowed also to set, delete or rename system attributes:\n",
    "version = None\n",
    "try:\n",
    "    table.attrs._f_rename(\"VERSION\", \"version\")\n",
    "    version = table.attrs.version\n",
    "except:\n",
    "    table.attrs._f_rename(\"version\", \"VERSION\")\n",
    "    version = table.attrs.VERSION\n",
    "\n",
    "version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. that’s better. If you would terminate your session now, you would be able to use the h5ls command to read the /detector/readout attributes from the file written to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened \"tmp/tutorial1.h5\" with sec2 driver.\r\n",
      "detector/readout         Dataset {10/Inf}\r\n",
      "    Attribute: CLASS scalar\r\n",
      "        Type:      5-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"TABLE\"\r\n",
      "    Attribute: FIELD_0_FILL scalar\r\n",
      "        Type:      native unsigned short\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_0_NAME scalar\r\n",
      "        Type:      8-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"ADCcount\"\r\n",
      "    Attribute: FIELD_1_FILL scalar\r\n",
      "        Type:      native unsigned char\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_1_NAME scalar\r\n",
      "        Type:      8-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"TDCcount\"\r\n",
      "    Attribute: FIELD_2_FILL scalar\r\n",
      "        Type:      native double\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_2_NAME scalar\r\n",
      "        Type:      6-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"energy\"\r\n",
      "    Attribute: FIELD_3_FILL scalar\r\n",
      "        Type:      native int\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_3_NAME scalar\r\n",
      "        Type:      6-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"grid_i\"\r\n",
      "    Attribute: FIELD_4_FILL scalar\r\n",
      "        Type:      native int\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_4_NAME scalar\r\n",
      "        Type:      6-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"grid_j\"\r\n",
      "    Attribute: FIELD_5_FILL scalar\r\n",
      "        Type:      native long\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_5_NAME scalar\r\n",
      "        Type:      8-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"idnumber\"\r\n",
      "    Attribute: FIELD_6_FILL scalar\r\n",
      "        Type:      1-byte null-terminated ASCII string\r\n",
      "        Data:  \"\"\r\n",
      "    Attribute: FIELD_6_NAME scalar\r\n",
      "        Type:      4-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"name\"\r\n",
      "    Attribute: FIELD_7_FILL scalar\r\n",
      "        Type:      native float\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_7_NAME scalar\r\n",
      "        Type:      8-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"pressure\"\r\n",
      "    Attribute: NROWS scalar\r\n",
      "        Type:      native long\r\n",
      "        Data:  10\r\n",
      "    Attribute: TITLE scalar\r\n",
      "        Type:      15-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"Readout example\"\r\n",
      "    Attribute: VERSION scalar\r\n",
      "        Type:      3-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"2.7\"\r\n",
      "    Attribute: is_gaby_the_best scalar\r\n",
      "        Type:      16-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"Hell yeah he is!\"\r\n",
      "    Attribute: tempScale scalar\r\n",
      "        Type:      7-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"Celsius\"\r\n",
      "    Attribute: temperature scalar\r\n",
      "        Type:      native double\r\n",
      "        Data:  18.4\r\n",
      "    Location:  1:3144\r\n",
      "    Links:     1\r\n",
      "    Chunks:    {1394} 65518 bytes\r\n",
      "    Storage:   470 logical bytes, 65518 allocated bytes, 0.72% utilization\r\n",
      "    Type:      struct {\r\n",
      "                   \"ADCcount\"         +0    native unsigned short\r\n",
      "                   \"TDCcount\"         +2    native unsigned char\r\n",
      "                   \"energy\"           +3    native double\r\n",
      "                   \"grid_i\"           +11   native int\r\n",
      "                   \"grid_j\"           +15   native int\r\n",
      "                   \"idnumber\"         +19   native long\r\n",
      "                   \"name\"             +27   16-byte null-terminated ASCII string\r\n",
      "                   \"pressure\"         +43   native float\r\n",
      "               } 47 bytes\r\n"
     ]
    }
   ],
   "source": [
    "! h5ls -vr tmp/tutorial1.h5/detector/readout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes are a useful mechanism to add persistent (meta) information to your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting object metadata\n",
    "Each object in PyTables has metadata information about the data in the file. Normally this meta-information is accessible through the node instance variables. Let’s take a look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/detector/readout (Table(10,)) 'Readout example'\n",
       "  description := {\n",
       "  \"ADCcount\": UInt16Col(shape=(), dflt=0, pos=0),\n",
       "  \"TDCcount\": UInt8Col(shape=(), dflt=0, pos=1),\n",
       "  \"energy\": Float64Col(shape=(), dflt=0.0, pos=2),\n",
       "  \"grid_i\": Int32Col(shape=(), dflt=0, pos=3),\n",
       "  \"grid_j\": Int32Col(shape=(), dflt=0, pos=4),\n",
       "  \"idnumber\": Int64Col(shape=(), dflt=0, pos=5),\n",
       "  \"name\": StringCol(itemsize=16, shape=(), dflt=b'', pos=6),\n",
       "  \"pressure\": Float32Col(shape=(), dflt=0.0, pos=7)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (1394,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file = open_file('tmp/tutorial1.h5', 'a')\n",
    "table = h5file.root.detector.readout\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object: /detector/readout (Table(10,)) 'Readout example'\n",
      "Table name: readout\n",
      "Table title: Readout example\n",
      "Number of rows in table: 10\n",
      "Table variable names with their type and shape:\n",
      "ADCcount := uint16, ()\n",
      "TDCcount := uint8, ()\n",
      "energy := float64, ()\n",
      "grid_i := int32, ()\n",
      "grid_j := int32, ()\n",
      "idnumber := int64, ()\n",
      "name := |S16, ()\n",
      "pressure := float32, ()\n"
     ]
    }
   ],
   "source": [
    "# Here, the name, title, nrows, colnames and coldtypes attributes (see Table for a complete attribute list) \n",
    "# of the Table object gives us quite a bit of information about the table data.\n",
    "print(\"Object:\", table)\n",
    "print(\"Table name:\", table.name)\n",
    "print(\"Table title:\", table.title)\n",
    "print(\"Number of rows in table:\", table.nrows)\n",
    "print(\"Table variable names with their type and shape:\")\n",
    "\n",
    "for name in table.colnames:\n",
    "    print(name, ':= %s, %s' % (table.coldtypes[name], table.coldtypes[name].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Table in module tables.table object:\n",
      "\n",
      "class Table(tables.tableextension.Table, tables.leaf.Leaf)\n",
      " |  This class represents heterogeneous datasets in an HDF5 file.\n",
      " |  \n",
      " |  Tables are leaves (see the Leaf class in :ref:`LeafClassDescr`) whose data\n",
      " |  consists of a unidimensional sequence of *rows*, where each row contains\n",
      " |  one or more *fields*.  Fields have an associated unique *name* and\n",
      " |  *position*, with the first field having position 0.  All rows have the same\n",
      " |  fields, which are arranged in *columns*.\n",
      " |  \n",
      " |  Fields can have any type supported by the Col class (see\n",
      " |  :ref:`ColClassDescr`) and its descendants, which support multidimensional\n",
      " |  data.  Moreover, a field can be *nested* (to an arbitrary depth), meaning\n",
      " |  that it includes further fields inside.  A field named x inside a nested\n",
      " |  field a in a table can be accessed as the field a/x (its *path name*) from\n",
      " |  the table.\n",
      " |  \n",
      " |  The structure of a table is declared by its description, which is made\n",
      " |  available in the Table.description attribute (see :class:`Table`).\n",
      " |  \n",
      " |  This class provides new methods to read, write and search table data\n",
      " |  efficiently.  It also provides special Python methods to allow accessing\n",
      " |  the table as a normal sequence or array (with extended slicing supported).\n",
      " |  \n",
      " |  PyTables supports *in-kernel* searches working simultaneously on several\n",
      " |  columns using complex conditions.  These are faster than selections using\n",
      " |  Python expressions.  See the :meth:`Table.where` method for more\n",
      " |  information on in-kernel searches.\n",
      " |  \n",
      " |  Non-nested columns can be *indexed*.  Searching an indexed column can be\n",
      " |  several times faster than searching a non-nested one.  Search methods\n",
      " |  automatically take advantage of indexing where available.\n",
      " |  \n",
      " |  When iterating a table, an object from the Row (see :ref:`RowClassDescr`)\n",
      " |  class is used.  This object allows to read and write data one row at a\n",
      " |  time, as well as to perform queries which are not supported by in-kernel\n",
      " |  syntax (at a much lower speed, of course).\n",
      " |  \n",
      " |  Objects of this class support access to individual columns via *natural\n",
      " |  naming* through the :attr:`Table.cols` accessor.  Nested columns are\n",
      " |  mapped to Cols instances, and non-nested ones to Column instances.\n",
      " |  See the Column class in :ref:`ColumnClassDescr` for examples of this\n",
      " |  feature.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  parentnode\n",
      " |      The parent :class:`Group` object.\n",
      " |  \n",
      " |      .. versionchanged:: 3.0\n",
      " |         Renamed from *parentNode* to *parentnode*.\n",
      " |  \n",
      " |  name : str\n",
      " |      The name of this node in its parent group.\n",
      " |  description\n",
      " |      An IsDescription subclass or a dictionary where the keys are the field\n",
      " |      names, and the values the type definitions. In addition, a pure NumPy\n",
      " |      dtype is accepted.  If None, the table metadata is read from disk,\n",
      " |      else, it's taken from previous parameters.\n",
      " |  title\n",
      " |      Sets a TITLE attribute on the HDF5 table entity.\n",
      " |  filters : Filters\n",
      " |      An instance of the Filters class that provides information about the\n",
      " |      desired I/O filters to be applied during the life of this object.\n",
      " |  expectedrows\n",
      " |      A user estimate about the number of rows that will be on table. If not\n",
      " |      provided, the default value is ``EXPECTED_ROWS_TABLE`` (see\n",
      " |      ``tables/parameters.py``).  If you plan to save bigger tables, try\n",
      " |      providing a guess; this will optimize the HDF5 B-Tree creation and\n",
      " |      management process time and memory used.\n",
      " |  chunkshape\n",
      " |      The shape of the data chunk to be read or written as a single HDF5 I/O\n",
      " |      operation. The filters are applied to those chunks of data. Its rank\n",
      " |      for tables has to be 1.  If ``None``, a sensible value is calculated\n",
      " |      based on the `expectedrows` parameter (which is recommended).\n",
      " |  byteorder\n",
      " |      The byteorder of the data *on-disk*, specified as 'little' or 'big'. If\n",
      " |      this is not specified, the byteorder is that of the platform, unless\n",
      " |      you passed a recarray as the `description`, in which case the recarray\n",
      " |      byteorder will be chosen.\n",
      " |  track_times\n",
      " |      Whether time data associated with the leaf are recorded (object\n",
      " |      access time, raw data modification time, metadata change time, object\n",
      " |      birth time); default True.  Semantics of these times depend on their\n",
      " |      implementation in the HDF5 library: refer to documentation of the\n",
      " |      H5O_info_t data structure.  As of HDF5 1.8.15, only ctime (metadata\n",
      " |      change time) is implemented.\n",
      " |  \n",
      " |      .. versionadded:: 3.4.3\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The instance variables below are provided in addition to those in\n",
      " |  Leaf (see :ref:`LeafClassDescr`).  Please note that there are several\n",
      " |  col* dictionaries to ease retrieving information about a column\n",
      " |  directly by its path name, avoiding the need to walk through\n",
      " |  Table.description or Table.cols.\n",
      " |  \n",
      " |  \n",
      " |  .. rubric:: Table attributes\n",
      " |  \n",
      " |  .. attribute:: coldescrs\n",
      " |  \n",
      " |      Maps the name of a column to its Col description (see\n",
      " |      :ref:`ColClassDescr`).\n",
      " |  \n",
      " |  .. attribute:: coldflts\n",
      " |  \n",
      " |      Maps the name of a column to its default value.\n",
      " |  \n",
      " |  .. attribute:: coldtypes\n",
      " |  \n",
      " |      Maps the name of a column to its NumPy data type.\n",
      " |  \n",
      " |  .. attribute:: colindexed\n",
      " |  \n",
      " |      Is the column which name is used as a key indexed?\n",
      " |  \n",
      " |  .. attribute:: colinstances\n",
      " |  \n",
      " |      Maps the name of a column to its Column (see\n",
      " |      :ref:`ColumnClassDescr`) or Cols (see :ref:`ColsClassDescr`)\n",
      " |      instance.\n",
      " |  \n",
      " |  .. attribute:: colnames\n",
      " |  \n",
      " |      A list containing the names of *top-level* columns in the table.\n",
      " |  \n",
      " |  .. attribute:: colpathnames\n",
      " |  \n",
      " |      A list containing the pathnames of *bottom-level* columns in\n",
      " |      the table.\n",
      " |  \n",
      " |      These are the leaf columns obtained when walking the table\n",
      " |      description left-to-right, bottom-first. Columns inside a\n",
      " |      nested column have slashes (/) separating name components in\n",
      " |      their pathname.\n",
      " |  \n",
      " |  .. attribute:: cols\n",
      " |  \n",
      " |      A Cols instance that provides *natural naming* access to\n",
      " |      non-nested (Column, see :ref:`ColumnClassDescr`) and nested\n",
      " |      (Cols, see :ref:`ColsClassDescr`) columns.\n",
      " |  \n",
      " |  .. attribute:: coltypes\n",
      " |  \n",
      " |      Maps the name of a column to its PyTables data type.\n",
      " |  \n",
      " |  .. attribute:: description\n",
      " |  \n",
      " |      A Description instance (see :ref:`DescriptionClassDescr`)\n",
      " |      reflecting the structure of the table.\n",
      " |  \n",
      " |  .. attribute:: extdim\n",
      " |  \n",
      " |      The index of the enlargeable dimension (always 0 for tables).\n",
      " |  \n",
      " |  .. attribute:: indexed\n",
      " |  \n",
      " |      Does this table have any indexed columns?\n",
      " |  \n",
      " |  .. attribute:: nrows\n",
      " |  \n",
      " |      The current number of rows in the table.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Table\n",
      " |      tables.tableextension.Table\n",
      " |      tables.hdf5extension.Leaf\n",
      " |      tables.hdf5extension.Node\n",
      " |      tables.leaf.Leaf\n",
      " |      tables.node.Node\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      Get a row or a range of rows from the table.\n",
      " |      \n",
      " |      If key argument is an integer, the corresponding table row is returned\n",
      " |      as a record of the current flavor. If key is a slice, the range of rows\n",
      " |      determined by it is returned as a structured array of the current\n",
      " |      flavor.\n",
      " |      \n",
      " |      In addition, NumPy-style point selections are supported.  In\n",
      " |      particular, if key is a list of row coordinates, the set of rows\n",
      " |      determined by it is returned.  Furthermore, if key is an array of\n",
      " |      boolean values, only the coordinates where key is True are returned.\n",
      " |      Note that for the latter to work it is necessary that key list would\n",
      " |      contain exactly as many rows as the table has.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          record = table[4]\n",
      " |          recarray = table[4:1000:2]\n",
      " |          recarray = table[[4,1000]]   # only retrieves rows 4 and 1000\n",
      " |          recarray = table[[True, False, ..., True]]\n",
      " |      \n",
      " |      Those statements are equivalent to::\n",
      " |      \n",
      " |          record = table.read(start=4)[0]\n",
      " |          recarray = table.read(start=4, stop=1000, step=2)\n",
      " |          recarray = table.read_coordinates([4,1000])\n",
      " |          recarray = table.read_coordinates([True, False, ..., True])\n",
      " |      \n",
      " |      Here, you can see how indexing can be used as a shorthand for the\n",
      " |      :meth:`Table.read` and :meth:`Table.read_coordinates` methods.\n",
      " |  \n",
      " |  __init__(self, parentnode, name, description=None, title='', filters=None, expectedrows=None, chunkshape=None, byteorder=None, _log=True, track_times=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over the table using a Row instance.\n",
      " |      \n",
      " |      This is equivalent to calling :meth:`Table.iterrows` with default\n",
      " |      arguments, i.e. it iterates over *all the rows* in the table.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      tableextension.Row : the table row iterator and field accessor\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          result = [ row['var2'] for row in table if row['var1'] <= 20 ]\n",
      " |      \n",
      " |      Which is equivalent to::\n",
      " |      \n",
      " |          result = [ row['var2'] for row in table.iterrows()\n",
      " |                                                  if row['var1'] <= 20 ]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      This provides column metainfo in addition to standard __str__\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |      Set a row or a range of rows in the table.\n",
      " |      \n",
      " |      It takes different actions depending on the type of the *key*\n",
      " |      parameter: if it is an integer, the corresponding table row is\n",
      " |      set to *value* (a record or sequence capable of being converted\n",
      " |      to the table structure).  If *key* is a slice, the row slice\n",
      " |      determined by it is set to *value* (a record array or sequence\n",
      " |      capable of being converted to the table structure).\n",
      " |      \n",
      " |      In addition, NumPy-style point selections are supported.  In\n",
      " |      particular, if key is a list of row coordinates, the set of rows\n",
      " |      determined by it is set to value.  Furthermore, if key is an array of\n",
      " |      boolean values, only the coordinates where key is True are set to\n",
      " |      values from value.  Note that for the latter to work it is necessary\n",
      " |      that key list would contain exactly as many rows as the table has.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          # Modify just one existing row\n",
      " |          table[2] = [456,'db2',1.2]\n",
      " |      \n",
      " |          # Modify two existing rows\n",
      " |          rows = numpy.rec.array([[457,'db1',1.2],[6,'de2',1.3]],\n",
      " |                                 formats='i4,a3,f8')\n",
      " |          table[1:30:2] = rows             # modify a table slice\n",
      " |          table[[1,3]] = rows              # only modifies rows 1 and 3\n",
      " |          table[[True,False,True]] = rows  # only modifies rows 0 and 2\n",
      " |      \n",
      " |      Which is equivalent to::\n",
      " |      \n",
      " |          table.modify_rows(start=2, rows=[456,'db2',1.2])\n",
      " |          rows = numpy.rec.array([[457,'db1',1.2],[6,'de2',1.3]],\n",
      " |                                 formats='i4,a3,f8')\n",
      " |          table.modify_rows(start=1, stop=3, step=2, rows=rows)\n",
      " |          table.modify_coordinates([1,3,2], rows)\n",
      " |          table.modify_coordinates([True, False, True], rows)\n",
      " |      \n",
      " |      Here, you can see how indexing can be used as a shorthand for the\n",
      " |      :meth:`Table.modify_rows` and :meth:`Table.modify_coordinates`\n",
      " |      methods.\n",
      " |  \n",
      " |  append(self, rows)\n",
      " |      Append a sequence of rows to the end of the table.\n",
      " |      \n",
      " |      The rows argument may be any object which can be converted to\n",
      " |      a structured array compliant with the table structure\n",
      " |      (otherwise, a ValueError is raised).  This includes NumPy\n",
      " |      structured arrays, lists of tuples or array records, and a\n",
      " |      string or Python buffer.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          import tables as tb\n",
      " |      \n",
      " |          class Particle(tb.IsDescription):\n",
      " |              name        = tb.StringCol(16, pos=1) # 16-character String\n",
      " |              lati        = tb.IntCol(pos=2)        # integer\n",
      " |              longi       = tb.IntCol(pos=3)        # integer\n",
      " |              pressure    = tb.Float32Col(pos=4)  # float  (single-precision)\n",
      " |              temperature = tb.FloatCol(pos=5)    # double (double-precision)\n",
      " |      \n",
      " |          fileh = tb.open_file('test4.h5', mode='w')\n",
      " |          table = fileh.create_table(fileh.root, 'table', Particle,\n",
      " |                                     \"A table\")\n",
      " |      \n",
      " |          # Append several rows in only one call\n",
      " |          table.append([(\"Particle:     10\", 10, 0, 10 * 10, 10**2),\n",
      " |                        (\"Particle:     11\", 11, -1, 11 * 11, 11**2),\n",
      " |                        (\"Particle:     12\", 12, -2, 12 * 12, 12**2)])\n",
      " |          fileh.close()\n",
      " |  \n",
      " |  append_where(self, dstTable, condition=None, condvars=None, start=None, stop=None, step=None)\n",
      " |      Append rows fulfilling the condition to the dstTable table.\n",
      " |      \n",
      " |      dstTable must be capable of taking the rows resulting from the query,\n",
      " |      i.e. it must have columns with the expected names and compatible\n",
      " |      types. The meaning of the other arguments is the same as in the\n",
      " |      :meth:`Table.where` method.\n",
      " |      \n",
      " |      The number of rows appended to dstTable is returned as a result.\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         The *whereAppend* method has been renamed into *append_where*.\n",
      " |  \n",
      " |  col(self, name)\n",
      " |      Get a column from the table.\n",
      " |      \n",
      " |      If a column called name exists in the table, it is read and returned as\n",
      " |      a NumPy object. If it does not exist, a KeyError is raised.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          narray = table.col('var2')\n",
      " |      \n",
      " |      That statement is equivalent to::\n",
      " |      \n",
      " |          narray = table.read(field='var2')\n",
      " |      \n",
      " |      Here you can see how this method can be used as a shorthand for the\n",
      " |      :meth:`Table.read` method.\n",
      " |  \n",
      " |  copy(self, newparent=None, newname=None, overwrite=False, createparents=False, **kwargs)\n",
      " |      Copy this table and return the new one.\n",
      " |      \n",
      " |      This method has the behavior and keywords described in\n",
      " |      :meth:`Leaf.copy`.  Moreover, it recognises the following additional\n",
      " |      keyword arguments.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sortby\n",
      " |          If specified, and sortby corresponds to a column with an index,\n",
      " |          then the copy will be sorted by this index.  If you want to ensure\n",
      " |          a fully sorted order, the index must be a CSI one.  A reverse\n",
      " |          sorted copy can be achieved by specifying a negative value for the\n",
      " |          step keyword.  If sortby is omitted or None, the original table\n",
      " |          order is used.\n",
      " |      checkCSI\n",
      " |          If true and a CSI index does not exist for the sortby column, an\n",
      " |          error will be raised.  If false (the default), it does nothing.\n",
      " |          You can use this flag in order to explicitly check for the\n",
      " |          existence of a CSI index.\n",
      " |      propindexes\n",
      " |          If true, the existing indexes in the source table are propagated\n",
      " |          (created) to the new one.  If false (the default), the indexes are\n",
      " |          not propagated.\n",
      " |  \n",
      " |  flush(self)\n",
      " |      Flush the table buffers.\n",
      " |  \n",
      " |  flush_rows_to_index(self, _lastrow=True)\n",
      " |      Add remaining rows in buffers to non-dirty indexes.\n",
      " |      \n",
      " |      This can be useful when you have chosen non-automatic indexing\n",
      " |      for the table (see the :attr:`Table.autoindex` property in\n",
      " |      :class:`Table`) and you want to update the indexes on it.\n",
      " |  \n",
      " |  get_enum(self, colname)\n",
      " |      Get the enumerated type associated with the named column.\n",
      " |      \n",
      " |      If the column named colname (a string) exists and is of an enumerated\n",
      " |      type, the corresponding Enum instance (see :ref:`EnumClassDescr`) is\n",
      " |      returned. If it is not of an enumerated type, a TypeError is raised. If\n",
      " |      the column does not exist, a KeyError is raised.\n",
      " |  \n",
      " |  get_where_list(self, condition, condvars=None, sort=False, start=None, stop=None, step=None)\n",
      " |      Get the row coordinates fulfilling the given condition.\n",
      " |      \n",
      " |      The coordinates are returned as a list of the current flavor.  sort\n",
      " |      means that you want to retrieve the coordinates ordered. The default is\n",
      " |      to not sort them.\n",
      " |      \n",
      " |      The meaning of the other arguments is the same as in the\n",
      " |      :meth:`Table.where` method.\n",
      " |  \n",
      " |  iterrows(self, start=None, stop=None, step=None)\n",
      " |      Iterate over the table using a Row instance.\n",
      " |      \n",
      " |      If a range is not supplied, *all the rows* in the table are iterated\n",
      " |      upon - you can also use the :meth:`Table.__iter__` special method for\n",
      " |      that purpose. If you want to iterate over a given *range of rows* in\n",
      " |      the table, you may use the start, stop and step parameters.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          When in the middle of a table row iterator, you should not\n",
      " |          use methods that can change the number of rows in the table\n",
      " |          (like :meth:`Table.append` or :meth:`Table.remove_rows`) or\n",
      " |          unexpected errors will happen.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      tableextension.Row : the table row iterator and field accessor\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          result = [ row['var2'] for row in table.iterrows(step=5)\n",
      " |                                                  if row['var1'] <= 20 ]\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         If the *start* parameter is provided and *stop* is None then the\n",
      " |         table is iterated from *start* to the last line.\n",
      " |         In PyTables < 3.0 only one element was returned.\n",
      " |  \n",
      " |  itersequence(self, sequence)\n",
      " |      Iterate over a sequence of row coordinates.\n",
      " |  \n",
      " |  itersorted(self, sortby, checkCSI=False, start=None, stop=None, step=None)\n",
      " |      Iterate table data following the order of the index of sortby\n",
      " |      column.\n",
      " |      \n",
      " |      The sortby column must have associated a full index.  If you want to\n",
      " |      ensure a fully sorted order, the index must be a CSI one.  You may want\n",
      " |      to use the checkCSI argument in order to explicitly check for the\n",
      " |      existence of a CSI index.\n",
      " |      \n",
      " |      The meaning of the start, stop and step arguments is the same as in\n",
      " |      :meth:`Table.read`.\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         If the *start* parameter is provided and *stop* is None then the\n",
      " |         table is iterated from *start* to the last line.\n",
      " |         In PyTables < 3.0 only one element was returned.\n",
      " |  \n",
      " |  modify_column(self, start=None, stop=None, step=None, column=None, colname=None)\n",
      " |      Modify one single column in the row slice [start:stop:step].\n",
      " |      \n",
      " |      The colname argument specifies the name of the column in the\n",
      " |      table to be modified with the data given in column.  This\n",
      " |      method returns the number of rows modified.  Should the\n",
      " |      modification exceed the length of the table, an IndexError is\n",
      " |      raised before changing data.\n",
      " |      \n",
      " |      The *column* argument may be any object which can be converted\n",
      " |      to a (record) array compliant with the structure of the column\n",
      " |      to be modified (otherwise, a ValueError is raised).  This\n",
      " |      includes NumPy (record) arrays, lists of scalars, tuples or\n",
      " |      array records, and a string or Python buffer.\n",
      " |  \n",
      " |  modify_columns(self, start=None, stop=None, step=None, columns=None, names=None)\n",
      " |      Modify a series of columns in the row slice [start:stop:step].\n",
      " |      \n",
      " |      The names argument specifies the names of the columns in the\n",
      " |      table to be modified with the data given in columns.  This\n",
      " |      method returns the number of rows modified.  Should the\n",
      " |      modification exceed the length of the table, an IndexError\n",
      " |      is raised before changing data.\n",
      " |      \n",
      " |      The columns argument may be any object which can be converted\n",
      " |      to a structured array compliant with the structure of the\n",
      " |      columns to be modified (otherwise, a ValueError is raised).\n",
      " |      This includes NumPy structured arrays, lists of tuples or array\n",
      " |      records, and a string or Python buffer.\n",
      " |  \n",
      " |  modify_coordinates(self, coords, rows)\n",
      " |      Modify a series of rows in positions specified in coords.\n",
      " |      \n",
      " |      The values in the selected rows will be modified with the data given in\n",
      " |      rows.  This method returns the number of rows modified.\n",
      " |      \n",
      " |      The possible values for the rows argument are the same as in\n",
      " |      :meth:`Table.append`.\n",
      " |  \n",
      " |  modify_rows(self, start=None, stop=None, step=None, rows=None)\n",
      " |      Modify a series of rows in the slice [start:stop:step].\n",
      " |      \n",
      " |      The values in the selected rows will be modified with the data given in\n",
      " |      rows.  This method returns the number of rows modified.  Should the\n",
      " |      modification exceed the length of the table, an IndexError is raised\n",
      " |      before changing data.\n",
      " |      \n",
      " |      The possible values for the rows argument are the same as in\n",
      " |      :meth:`Table.append`.\n",
      " |  \n",
      " |  read(self, start=None, stop=None, step=None, field=None, out=None)\n",
      " |      Get data in the table as a (record) array.\n",
      " |      \n",
      " |      The start, stop and step parameters can be used to select only\n",
      " |      a *range of rows* in the table. Their meanings are the same as\n",
      " |      in the built-in Python slices.\n",
      " |      \n",
      " |      If field is supplied only the named column will be selected.\n",
      " |      If the column is not nested, an *array* of the current flavor\n",
      " |      will be returned; if it is, a *structured array* will be used\n",
      " |      instead.  If no field is specified, all the columns will be\n",
      " |      returned in a structured array of the current flavor.\n",
      " |      \n",
      " |      Columns under a nested column can be specified in the field\n",
      " |      parameter by using a slash character (/) as a separator (e.g.\n",
      " |      'position/x').\n",
      " |      \n",
      " |      The out parameter may be used to specify a NumPy array to\n",
      " |      receive the output data.  Note that the array must have the\n",
      " |      same size as the data selected with the other parameters.\n",
      " |      Note that the array's datatype is not checked and no type\n",
      " |      casting is performed, so if it does not match the datatype on\n",
      " |      disk, the output will not be correct.\n",
      " |      \n",
      " |      When specifying a single nested column with the field parameter,\n",
      " |      and supplying an output buffer with the out parameter, the\n",
      " |      output buffer must contain all columns in the table.\n",
      " |      The data in all columns will be read into the output buffer.\n",
      " |      However, only the specified nested column will be returned from\n",
      " |      the method call.\n",
      " |      \n",
      " |      When data is read from disk in NumPy format, the output will be\n",
      " |      in the current system's byteorder, regardless of how it is\n",
      " |      stored on disk. If the out parameter is specified, the output\n",
      " |      array also must be in the current system's byteorder.\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         Added the *out* parameter.  Also the start, stop and step\n",
      " |         parameters now behave like in slice.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Reading the entire table::\n",
      " |      \n",
      " |          t.read()\n",
      " |      \n",
      " |      Reading record n. 6::\n",
      " |      \n",
      " |          t.read(6, 7)\n",
      " |      \n",
      " |      Reading from record n. 6 to the end of the table::\n",
      " |      \n",
      " |          t.read(6)\n",
      " |  \n",
      " |  read_coordinates(self, coords, field=None)\n",
      " |      Get a set of rows given their indexes as a (record) array.\n",
      " |      \n",
      " |      This method works much like the :meth:`Table.read` method, but it uses\n",
      " |      a sequence (coords) of row indexes to select the wanted columns,\n",
      " |      instead of a column range.\n",
      " |      \n",
      " |      The selected rows are returned in an array or structured array of the\n",
      " |      current flavor.\n",
      " |  \n",
      " |  read_sorted(self, sortby, checkCSI=False, field=None, start=None, stop=None, step=None)\n",
      " |      Read table data following the order of the index of sortby column.\n",
      " |      \n",
      " |      The sortby column must have associated a full index.  If you want to\n",
      " |      ensure a fully sorted order, the index must be a CSI one.  You may want\n",
      " |      to use the checkCSI argument in order to explicitly check for the\n",
      " |      existence of a CSI index.\n",
      " |      \n",
      " |      If field is supplied only the named column will be selected.  If the\n",
      " |      column is not nested, an *array* of the current flavor will be\n",
      " |      returned; if it is, a *structured array* will be used instead.  If no\n",
      " |      field is specified, all the columns will be returned in a structured\n",
      " |      array of the current flavor.\n",
      " |      \n",
      " |      The meaning of the start, stop and step arguments is the same as in\n",
      " |      :meth:`Table.read`.\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         The start, stop and step parameters now behave like in slice.\n",
      " |  \n",
      " |  read_where(self, condition, condvars=None, field=None, start=None, stop=None, step=None)\n",
      " |      Read table data fulfilling the given *condition*.\n",
      " |      \n",
      " |      This method is similar to :meth:`Table.read`, having their common\n",
      " |      arguments and return values the same meanings. However, only the rows\n",
      " |      fulfilling the *condition* are included in the result.\n",
      " |      \n",
      " |      The meaning of the other arguments is the same as in the\n",
      " |      :meth:`Table.where` method.\n",
      " |  \n",
      " |  reindex(self)\n",
      " |      Recompute all the existing indexes in the table.\n",
      " |      \n",
      " |      This can be useful when you suspect that, for any reason, the\n",
      " |      index information for columns is no longer valid and want to\n",
      " |      rebuild the indexes on it.\n",
      " |  \n",
      " |  reindex_dirty(self)\n",
      " |      Recompute the existing indexes in table, *if* they are dirty.\n",
      " |      \n",
      " |      This can be useful when you have set :attr:`Table.autoindex`\n",
      " |      (see :class:`Table`) to false for the table and you want to\n",
      " |      update the indexes after a invalidating index operation\n",
      " |      (:meth:`Table.remove_rows`, for example).\n",
      " |  \n",
      " |  remove_row(self, n)\n",
      " |      Removes a row from the table.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          The index of the row to remove.\n",
      " |      \n",
      " |      \n",
      " |      .. versionadded:: 3.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Remove row 15::\n",
      " |      \n",
      " |          table.remove_row(15)\n",
      " |      \n",
      " |      Which is equivalent to::\n",
      " |      \n",
      " |          table.remove_rows(15, 16)\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          This is not equivalent to::\n",
      " |      \n",
      " |              table.remove_rows(15)\n",
      " |  \n",
      " |  remove_rows(self, start=None, stop=None, step=None)\n",
      " |      Remove a range of rows in the table.\n",
      " |      \n",
      " |      If only start is supplied, that row and all following will be deleted.\n",
      " |      If a range is supplied, i.e. both the start and stop parameters are\n",
      " |      passed, all the rows in the range are removed.\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         The start, stop and step parameters now behave like in slice.\n",
      " |      \n",
      " |      .. seealso:: remove_row()\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start : int\n",
      " |          Sets the starting row to be removed. It accepts negative values\n",
      " |          meaning that the count starts from the end.  A value of 0 means the\n",
      " |          first row.\n",
      " |      stop : int\n",
      " |          Sets the last row to be removed to stop-1, i.e. the end point is\n",
      " |          omitted (in the Python range() tradition). Negative values are also\n",
      " |          accepted. If None all rows after start will be removed.\n",
      " |      step : int\n",
      " |          The step size between rows to remove.\n",
      " |      \n",
      " |          .. versionadded:: 3.0\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      Removing rows from 5 to 10 (excluded)::\n",
      " |      \n",
      " |          t.remove_rows(5, 10)\n",
      " |      \n",
      " |      Removing all rows starting from the 10th::\n",
      " |      \n",
      " |          t.remove_rows(10)\n",
      " |      \n",
      " |      Removing the 6th row::\n",
      " |      \n",
      " |          t.remove_rows(6, 7)\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          removing a single row can be done using the specific\n",
      " |          :meth:`remove_row` method.\n",
      " |  \n",
      " |  where(self, condition, condvars=None, start=None, stop=None, step=None)\n",
      " |      Iterate over values fulfilling a condition.\n",
      " |      \n",
      " |      This method returns a Row iterator (see :ref:`RowClassDescr`) which\n",
      " |      only selects rows in the table that satisfy the given condition (an\n",
      " |      expression-like string).\n",
      " |      \n",
      " |      The condvars mapping may be used to define the variable names appearing\n",
      " |      in the condition. condvars should consist of identifier-like strings\n",
      " |      pointing to Column (see :ref:`ColumnClassDescr`) instances *of this\n",
      " |      table*, or to other values (which will be converted to arrays). A\n",
      " |      default set of condition variables is provided where each top-level,\n",
      " |      non-nested column with an identifier-like name appears. Variables in\n",
      " |      condvars override the default ones.\n",
      " |      \n",
      " |      When condvars is not provided or None, the current local and global\n",
      " |      namespace is sought instead of condvars. The previous mechanism is\n",
      " |      mostly intended for interactive usage. To disable it, just specify a\n",
      " |      (maybe empty) mapping as condvars.\n",
      " |      \n",
      " |      If a range is supplied (by setting some of the start, stop or step\n",
      " |      parameters), only the rows in that range and fulfilling the condition\n",
      " |      are used. The meaning of the start, stop and step parameters is the\n",
      " |      same as for Python slices.\n",
      " |      \n",
      " |      When possible, indexed columns participating in the condition will be\n",
      " |      used to speed up the search. It is recommended that you place the\n",
      " |      indexed columns as left and out in the condition as possible. Anyway,\n",
      " |      this method has always better performance than regular Python\n",
      " |      selections on the table.\n",
      " |      \n",
      " |      You can mix this method with regular Python selections in order to\n",
      " |      support even more complex queries. It is strongly recommended that you\n",
      " |      pass the most restrictive condition as the parameter to this method if\n",
      " |      you want to achieve maximum performance.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          When in the middle of a table row iterator, you should not\n",
      " |          use methods that can change the number of rows in the table\n",
      " |          (like :meth:`Table.append` or :meth:`Table.remove_rows`) or\n",
      " |          unexpected errors will happen.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      ::\n",
      " |      \n",
      " |          >>> passvalues = [ row['col3'] for row in\n",
      " |          ...                table.where('(col1 > 0) & (col2 <= 20)', step=5)\n",
      " |          ...                if your_function(row['col2']) ]\n",
      " |          >>> print(\"Values that pass the cuts:\", passvalues)\n",
      " |      \n",
      " |      .. note::\n",
      " |      \n",
      " |          A special care should be taken when the query condition includes\n",
      " |          string literals.  Indeed Python 2 string literals are string of\n",
      " |          bytes while Python 3 strings are unicode objects.\n",
      " |      \n",
      " |          Let's assume that the table ``table`` has the following\n",
      " |          structure::\n",
      " |      \n",
      " |              class Record(IsDescription):\n",
      " |                  col1 = StringCol(4)  # 4-character String of bytes\n",
      " |                  col2 = IntCol()\n",
      " |                  col3 = FloatCol()\n",
      " |      \n",
      " |          The type of \"col1\" do not change depending on the Python version\n",
      " |          used (of course) and it always corresponds to strings of bytes.\n",
      " |      \n",
      " |          Any condition involving \"col1\" should be written using the\n",
      " |          appropriate type for string literals in order to avoid\n",
      " |          :exc:`TypeError`\\ s.\n",
      " |      \n",
      " |          The code below will work fine in Python 2 but will fail with a\n",
      " |          :exc:`TypeError` in Python 3::\n",
      " |      \n",
      " |              condition = 'col1 == \"AAAA\"'\n",
      " |              for record in table.where(condition):  # TypeError in Python3\n",
      " |                  # do something with \"record\"\n",
      " |      \n",
      " |          The reason is that in Python 3 \"condition\" implies a comparison\n",
      " |          between a string of bytes (\"col1\" contents) and an unicode literal\n",
      " |          (\"AAAA\").\n",
      " |      \n",
      " |          The correct way to write the condition is::\n",
      " |      \n",
      " |              condition = 'col1 == b\"AAAA\"'\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         The start, stop and step parameters now behave like in slice.\n",
      " |  \n",
      " |  will_query_use_indexing(self, condition, condvars=None)\n",
      " |      Will a query for the condition use indexing?\n",
      " |      \n",
      " |      The meaning of the condition and *condvars* arguments is the same as in\n",
      " |      the :meth:`Table.where` method. If condition can use indexing, this\n",
      " |      method returns a frozenset with the path names of the columns whose\n",
      " |      index is usable. Otherwise, it returns an empty list.\n",
      " |      \n",
      " |      This method is mainly intended for testing. Keep in mind that changing\n",
      " |      the set of indexed columns or their dirtiness may make this method\n",
      " |      return different values for the same arguments at different times.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  autoindex\n",
      " |      Automatically keep column indexes up to date?\n",
      " |      \n",
      " |      Setting this value states whether existing indexes should be\n",
      " |      automatically updated after an append operation or recomputed\n",
      " |      after an index-invalidating operation (i.e. removal and\n",
      " |      modification of rows).  The default is true.\n",
      " |      \n",
      " |      This value gets into effect whenever a column is altered.  If you\n",
      " |      don't have automatic indexing activated and you want to do an an\n",
      " |      immediate update use `Table.flush_rows_to_index()`; for an immediate\n",
      " |      reindexing of invalidated indexes, use `Table.reindex_dirty()`.\n",
      " |      \n",
      " |      This value is persistent.\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         The *autoIndex* property has been renamed into *autoindex*.\n",
      " |  \n",
      " |  colindexes\n",
      " |      A dictionary with the indexes of the indexed columns.\n",
      " |  \n",
      " |  dtype\n",
      " |      The NumPy ``dtype`` that most closely matches this table.\n",
      " |  \n",
      " |  indexedcolpathnames\n",
      " |      List of pathnames of indexed columns in the table.\n",
      " |  \n",
      " |  row\n",
      " |      The associated Row instance (see :ref:`RowClassDescr`).\n",
      " |  \n",
      " |  rowsize\n",
      " |      The size in bytes of each row in the table.\n",
      " |  \n",
      " |  shape\n",
      " |      The shape of this table.\n",
      " |  \n",
      " |  size_in_memory\n",
      " |      The size of this table's data in bytes when it is fully loaded into\n",
      " |      memory.  This may be used in combination with size_on_disk to calculate\n",
      " |      the compression ratio of the data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tables.tableextension.Table:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from tables.tableextension.Table:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tables.leaf.Leaf:\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the length of the main dimension of the leaf data.\n",
      " |      \n",
      " |      Please note that this may raise an OverflowError on 32-bit platforms\n",
      " |      for datasets having more than 2**31-1 rows.  This is a limitation of\n",
      " |      Python that you can work around by using the nrows or shape attributes.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      The string representation for this object is its pathname in the\n",
      " |      HDF5 object tree plus some additional metainfo.\n",
      " |  \n",
      " |  close(self, flush=True)\n",
      " |      Close this node in the tree.\n",
      " |      \n",
      " |      This method is completely equivalent to :meth:`Leaf._f_close`.\n",
      " |  \n",
      " |  del_attr(self, name)\n",
      " |      Delete a PyTables attribute from this node.\n",
      " |      \n",
      " |      This method has the behavior described in :meth:`Node_f_delAttr`.\n",
      " |  \n",
      " |  get_attr(self, name)\n",
      " |      Get a PyTables attribute from this node.\n",
      " |      \n",
      " |      This method has the behavior described in :meth:`Node._f_getattr`.\n",
      " |  \n",
      " |  isvisible(self)\n",
      " |      Is this node visible?\n",
      " |      \n",
      " |      This method has the behavior described in :meth:`Node._f_isvisible()`.\n",
      " |  \n",
      " |  move(self, newparent=None, newname=None, overwrite=False, createparents=False)\n",
      " |      Move or rename this node.\n",
      " |      \n",
      " |      This method has the behavior described in :meth:`Node._f_move`\n",
      " |  \n",
      " |  remove(self)\n",
      " |      Remove this node from the hierarchy.\n",
      " |      \n",
      " |      This method has the behavior described\n",
      " |      in :meth:`Node._f_remove`. Please note that there is no recursive flag\n",
      " |      since leaves do not have child nodes.\n",
      " |  \n",
      " |  rename(self, newname)\n",
      " |      Rename this node in place.\n",
      " |      \n",
      " |      This method has the behavior described in :meth:`Node._f_rename()`.\n",
      " |  \n",
      " |  set_attr(self, name, value)\n",
      " |      Set a PyTables attribute for this node.\n",
      " |      \n",
      " |      This method has the behavior described in :meth:`Node._f_setattr()`.\n",
      " |  \n",
      " |  truncate(self, size)\n",
      " |      Truncate the main dimension to be size rows.\n",
      " |      \n",
      " |      If the main dimension previously was larger than this size, the extra\n",
      " |      data is lost.  If the main dimension previously was shorter, it is\n",
      " |      extended, and the extended part is filled with the default values.\n",
      " |      \n",
      " |      The truncation operation can only be applied to *enlargeable* datasets,\n",
      " |      else a TypeError will be raised.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tables.leaf.Leaf:\n",
      " |  \n",
      " |  attrs\n",
      " |      The associated `AttributeSet` instance.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      tables.attributeset.AttributeSet : container for the HDF5 attributes\n",
      " |  \n",
      " |  chunkshape\n",
      " |      The HDF5 chunk size for chunked leaves (a tuple).\n",
      " |      \n",
      " |      This is read-only because you cannot change the chunk size of a\n",
      " |      leaf once it has been created.\n",
      " |  \n",
      " |  filters\n",
      " |      Filter properties for this leaf.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Filters\n",
      " |  \n",
      " |  flavor\n",
      " |      The type of data object read from this leaf.\n",
      " |      \n",
      " |      It can be any of 'numpy' or 'python'.\n",
      " |      \n",
      " |      You can (and are encouraged to) use this property to get, set\n",
      " |      and delete the FLAVOR HDF5 attribute of the leaf. When the leaf\n",
      " |      has no such attribute, the default flavor is used..\n",
      " |  \n",
      " |  maindim\n",
      " |      The dimension along which iterators work.\n",
      " |      \n",
      " |      Its value is 0 (i.e. the first dimension) when the dataset is not\n",
      " |      extendable, and self.extdim (where available) for extendable ones.\n",
      " |  \n",
      " |  name\n",
      " |      The name of this node in its parent group (This is an easier-to-write alias of :attr:`Node._v_name`).\n",
      " |  \n",
      " |  ndim\n",
      " |      The number of dimensions of the leaf data.\n",
      " |      \n",
      " |      .. versionadded: 2.4\n",
      " |  \n",
      " |  object_id\n",
      " |      A node identifier, which may change from run to run.\n",
      " |      (This is an easier-to-write alias of :attr:`Node._v_objectid`).\n",
      " |      \n",
      " |      .. versionchanged:: 3.0\n",
      " |         The *objectID* property has been renamed into *object_id*.\n",
      " |  \n",
      " |  size_on_disk\n",
      " |      The size of this leaf's data in bytes as it is stored on disk.  If the\n",
      " |      data is compressed, this shows the compressed size.  In the case of\n",
      " |      uncompressed, chunked data, this may be slightly larger than the amount\n",
      " |      of data, due to partially filled chunks.\n",
      " |  \n",
      " |  title\n",
      " |      A description of this node. A shorthand for TITLE attribute.\n",
      " |  \n",
      " |  track_times\n",
      " |      Whether timestamps for the leaf are recorded\n",
      " |      \n",
      " |      If the leaf is not a dataset, this will fail with HDF5ExtError.\n",
      " |      \n",
      " |      The track times dataset creation property does not seem to\n",
      " |      survive closing and reopening as of HDF5 1.8.17.  Currently,\n",
      " |      it may be more accurate to test whether the ctime for the\n",
      " |      dataset is 0:\n",
      " |      track_times = (leaf._get_obj_timestamps().ctime == 0)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tables.node.Node:\n",
      " |  \n",
      " |  __del__(self)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can interactively retrieve general information about the public objects in PyTables by asking for help:\n",
    "help(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info on the object: /columns/pressure (Array(3,)) 'Pressure column selection'\n",
      "  atom := Float64Atom(shape=(), dflt=0.0)\n",
      "  maindim := 0\n",
      "  flavor := 'python'\n",
      "  byteorder := 'little'\n",
      "  chunkshape := None\n",
      "  shape: ==> (3,)\n",
      "  title: ==> Pressure column selection\n",
      "  atom: ==> Float64Atom(shape=(), dflt=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Search the file tree for the \"columns\" node and extract the pressure column object \n",
    "pressureObject = h5file.get_node(where=\"/columns\", name=\"pressure\")\n",
    "print(\"Info on the object:\", repr(pressureObject))\n",
    "print(\"  shape: ==>\", pressureObject.shape)\n",
    "print(\"  title: ==>\", pressureObject.title)\n",
    "print(\"  atom: ==>\", pressureObject.atom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that we have used the `File.get_node()` method of the File class to access a node in the tree, instead of the natural naming method. Both are useful, and depending on the context you will prefer one or the other. `File.get_node()` has the advantage that it can get a node from the pathname string (as in this example) and can also act as a filter to show only nodes in a particular location that are instances of class classname. In general, however, I consider natural naming to be more elegant and easier to use, especially if you are using the name completion capability present in interactive console. Try this powerful combination of natural naming and completion capabilities present in most Python consoles, and see how pleasant it is to browse the object tree (well, as pleasant as such an activity can be).\n",
    "\n",
    "If you look at the type attribute of the `pressureObject` object, you can verify that it is a `float64` array. By looking at its shape attribute, you can deduce that the array on disk is unidimensional and has 3 elements. See Array or the internal doc strings for the complete Array attribute list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from Array objects\n",
    "Once you have found the desired Array, use the `read()` method of the Array object to retrieve its data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25.0, 36.0, 49.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pressureArray = pressureObject.read()\n",
    "pressureArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pressureArray is an object of type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(\"pressureArray is an object of type:\", type(pressureArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nameArray is an object of type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "nameArray = h5file.root.columns.name.read()\n",
    "print(\"nameArray is an object of type:\", type(nameArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data on arrays nameArray and pressureArray:\n",
      "b'Particle:      5' --> 25.0\n",
      "b'Particle:      6' --> 36.0\n",
      "b'Particle:      7' --> 49.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Data on arrays nameArray and pressureArray:\")\n",
    "for i in range(pressureObject.shape[0]):\n",
    "    print(nameArray[i], \"-->\", pressureArray[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the `Array.read()` method returns an authentic NumPy object for the `pressureObject` instance by looking at the output of the `type()` call. A `read()` of the nameArray object instance returns a native Python list (of strings). The type of the object saved is stored as an HDF5 attribute (named FLAVOR) for objects on disk. This attribute is then read as Array meta-information (accessible through in the Array.attrs.FLAVOR variable), enabling the read array to be converted into the original object. This provides a means to save a large variety of objects as arrays with the guarantee that you will be able to later recover them in their original form. See `File.create_array()` for a complete list of supported objects for the Array object class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commiting data to tables and arrays\n",
    "We have seen how to create tables and arrays and how to browse both data and metadata in the object tree. Let’s examine more closely now one of the most powerful capabilities of PyTables, namely, how to modify already created tables and arrays.\n",
    "\n",
    "# Appending data to an existing table\n",
    "Now, let’s have a look at how we can add records to an existing table on disk. Let’s use our well-known readout Table object and append some new values to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = h5file.root.detector.readout\n",
    "particle = table.row\n",
    "\n",
    "for i in range(10, 15):\n",
    "    particle['name']  = 'Particle: %6d' % (i)\n",
    "    particle['TDCcount'] = i % 256\n",
    "    particle['ADCcount'] = (i * 256) % (1 << 16)\n",
    "    particle['grid_i'] = i\n",
    "    particle['grid_j'] = 10 - i\n",
    "    particle['pressure'] = float(i*i)\n",
    "    particle['energy'] = float(particle['pressure'] ** 4)\n",
    "    particle['idnumber'] = i * (2 ** 34)\n",
    "    particle.append()\n",
    "\n",
    "table.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s the same method we used to fill a new table. PyTables knows that this table is on disk, and when you add new records, they are appended to the end of the table.\n",
    "\n",
    "If you look carefully at the code you will see that we have used the table.row attribute to create a table row and fill it with the new values. Each time that its `append()` method is called, the actual row is committed to the output buffer and the row pointer is incremented to point to the next table record. When the buffer is full, the data is saved on disk, and the buffer is reused again for the next cycle.\n",
    "\n",
    "_Caveat emptor:_ Do not forget to always call the flush() method after a write operation, or else your tables will not be updated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Particle:      0' |         0.0 |           0 |      0 |     10 |        0 \\|\n",
      "b'Particle:      1' |         1.0 |           1 |      1 |      9 |        1 \\|\n",
      "b'Particle:      2' |         4.0 |         256 |      2 |      8 |        2 \\|\n",
      "b'Particle:      3' |         9.0 |        6561 |      3 |      7 |        3 \\|\n",
      "b'Particle:      4' |        16.0 |   6.554e+04 |      4 |      6 |        4 \\|\n",
      "b'Particle:      5' |        25.0 |   3.906e+05 |      5 |      5 |        5 \\|\n",
      "b'Particle:      6' |        36.0 |    1.68e+06 |      6 |      4 |        6 \\|\n",
      "b'Particle:      7' |        49.0 |   5.765e+06 |      7 |      3 |        7 \\|\n",
      "b'Particle:      8' |        64.0 |   1.678e+07 |      8 |      2 |        8 \\|\n",
      "b'Particle:      9' |        81.0 |   4.305e+07 |      9 |      1 |        9 \\|\n",
      "b'Particle:     10' |       100.0 |       1e+08 |     10 |      0 |       10 \\|\n",
      "b'Particle:     11' |       121.0 |   2.144e+08 |     11 |     -1 |       11 \\|\n",
      "b'Particle:     12' |       144.0 |     4.3e+08 |     12 |     -2 |       12 \\|\n",
      "b'Particle:     13' |       169.0 |   8.157e+08 |     13 |     -3 |       13 \\|\n",
      "b'Particle:     14' |       196.0 |   1.476e+09 |     14 |     -4 |       14 \\|\n"
     ]
    }
   ],
   "source": [
    "# Let’s have a look at some rows in the modified table and verify that our new data has been appended:\n",
    "for r in table.iterrows():\n",
    "    print(\"%-16s | %11.1f | %11.4g | %6d | %6d | %8d \\|\" % \\\n",
    "          (r['name'], r['pressure'], r['energy'], r['grid_i'], r['grid_j'],\n",
    "           r['TDCcount']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying data in tables\n",
    "Ok, until now, we’ve been only reading and writing (appending) values to our tables. But there are times that you need to modify your data once you have saved it on disk (this is specially true when you need to modify the real world data to adapt your goals ;). Let’s see how we can modify the values that were saved in our existing tables. We will start modifying single cells in the first row of the Particle table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before modif--> (0, 0, 0., 0, 10, 0, b'Particle:      0', 0.)\n",
      "After modifying first row of ADCcount--> (0, 1, 0., 0, 10, 0, b'Particle:      0', 0.)\n",
      "After modifying first row of energy--> (0, 1, 2., 0, 10, 0, b'Particle:      0', 0.)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before modif-->\", table[0])\n",
    "\n",
    "table.cols.TDCcount[0] = 1\n",
    "print(\"After modifying first row of ADCcount-->\", table[0])\n",
    "\n",
    "table.cols.energy[0] = 2\n",
    "print(\"After modifying first row of energy-->\", table[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After modifying slice [2:5] of TDCcount--> [(   0, 1, 2.000e+00, 0, 10,           0, b'Particle:      0',  0.)\n",
      " ( 256, 1, 2.000e+00, 1,  9, 17179869184, b'Particle:      1',  1.)\n",
      " ( 512, 2, 2.560e+02, 2,  8, 34359738368, b'Particle:      2',  4.)\n",
      " ( 768, 3, 6.561e+03, 3,  7, 51539607552, b'Particle:      3',  9.)\n",
      " (1024, 4, 3.000e+00, 4,  6, 68719476736, b'Particle:      4', 16.)]\n",
      "After modifying slice [1:9:3] of energy--> [(   0, 1, 2.0000000e+00, 0, 10,            0, b'Particle:      0',  0.)\n",
      " ( 256, 1, 2.0000000e+00, 1,  9,  17179869184, b'Particle:      1',  1.)\n",
      " ( 512, 2, 2.5600000e+02, 2,  8,  34359738368, b'Particle:      2',  4.)\n",
      " ( 768, 3, 6.5610000e+03, 3,  7,  51539607552, b'Particle:      3',  9.)\n",
      " (1024, 4, 3.0000000e+00, 4,  6,  68719476736, b'Particle:      4', 16.)\n",
      " (1280, 5, 3.9062500e+05, 5,  5,  85899345920, b'Particle:      5', 25.)\n",
      " (1536, 6, 1.6796160e+06, 6,  4, 103079215104, b'Particle:      6', 36.)\n",
      " (1792, 7, 4.0000000e+00, 7,  3, 120259084288, b'Particle:      7', 49.)\n",
      " (2048, 8, 1.6777216e+07, 8,  2, 137438953472, b'Particle:      8', 64.)]\n"
     ]
    }
   ],
   "source": [
    "# We can modify complete ranges of columns as well:\n",
    "table.cols.TDCcount[2:5] = [2,3,4]\n",
    "print(\"After modifying slice [2:5] of TDCcount-->\", table[0:5])\n",
    "\n",
    "table.cols.energy[1:9:3] = [2,3,4]\n",
    "print(\"After modifying slice [1:9:3] of energy-->\", table[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember** that column TDCcount is the second one, and that energy is the third. Look for more info on modifying columns in `Column.__setitem__()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTables also lets you modify complete sets of rows at the same time. As a demonstration of these capability, see the next example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.modify_rows(\n",
    "    start=1, step=3,\n",
    "    rows=[(1, 2, 3.0, 4, 5, 6, 'Particle:   None', 8.0),\n",
    "          (2, 4, 6.0, 8, 10, 12, 'Particle: None*2', 16.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After modifying the complete third row--> [(  0, 1, 2.000e+00, 0, 10,           0, b'Particle:      0',  0.)\n",
      " (  1, 2, 3.000e+00, 4,  5,           6, b'Particle:   None',  8.)\n",
      " (512, 2, 2.560e+02, 2,  8, 34359738368, b'Particle:      2',  4.)\n",
      " (768, 3, 6.561e+03, 3,  7, 51539607552, b'Particle:      3',  9.)\n",
      " (  2, 4, 6.000e+00, 8, 10,          12, b'Particle: None*2', 16.)]\n"
     ]
    }
   ],
   "source": [
    "print(\"After modifying the complete third row-->\", table[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `modify_rows()` call has modified the rows second and fifth, and it returned the number of modified rows.\n",
    "\n",
    "Apart of `Table.modify_rows()`, there exists another method, called `Table.modify_column()` to modify specific columns as well.\n",
    "\n",
    "Finally, it exists another way of modifying tables that is generally more handy than the described above. This new way uses the method `Row.update()` of the Row instance that is attached to every table, so it is meant to be used in table iterators. Look at the next example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After modifying energy column (where TDCcount <=2) -->\n",
      " [(  0, 1, 2.000e+00, 0, 10,           0, b'Particle:      0', 0.)\n",
      " (  1, 2, 4.000e+00, 4,  5,           6, b'Particle:   None', 8.)\n",
      " (512, 2, 4.000e+00, 2,  8, 34359738368, b'Particle:      2', 4.)\n",
      " (768, 3, 6.561e+03, 3,  7, 51539607552, b'Particle:      3', 9.)]\n"
     ]
    }
   ],
   "source": [
    "for row in table.where('TDCcount <= 2'):\n",
    "    row['energy'] = row['TDCcount']*2\n",
    "    row.update()\n",
    "\n",
    "print(\"After modifying energy column (where TDCcount <=2) -->\\n\", table[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The authors find this way of updating tables (i.e. using `Row.update()`) to be both convenient and efficient. Please make sure to use it extensively.\n",
    "\n",
    "_Caveat emptor:_ Currently, `Row.update()` will not work (the table will not be updated) if the loop is broken with break statement. A possible workaround consists in manually flushing the row internal buffer by calling `row._flushModRows()` just before the break statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying data in arrays\n",
    "We are going now to see how to modify data in array objects. The basic way to do this is through the use of `Array.__setitem__()` special method. Let’s see at how modify data on the `pressureObject` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before modif --> [1.0, 2.1, 2.0]\n",
      "First modif --> [2.0, 2.1, 2.0]\n",
      "Second modif --> [2.0, 2.1, 3.5]\n",
      "Third modif --> [1.0, 2.1, 2.0]\n"
     ]
    }
   ],
   "source": [
    "pressureObject = h5file.root.columns.pressure\n",
    "print(\"Before modif -->\", pressureObject[:])\n",
    "\n",
    "pressureObject[0] = 2\n",
    "print(\"First modif -->\", pressureObject[:])\n",
    "\n",
    "pressureObject[1:3] = [2.1, 3.5]\n",
    "print(\"Second modif -->\", pressureObject[:])\n",
    "\n",
    "pressureObject[::2] = [1,2]\n",
    "print(\"Third modif -->\", pressureObject[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, in general, you can use any combination of (multidimensional) extended slicing.\n",
    "With the sole exception that you cannot use negative values for step to refer to indexes that you want to modify. See `Array.__getitem__()` for more examples on how to use extended slicing in PyTables objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before modif --> [b'Particle:     -3', b'Particle:      0', b'Particle:     -5']\n",
      "First modif --> [b'Particle:   None', b'Particle:      0', b'Particle:     -5']\n",
      "Second modif --> [b'Particle:   None', b'Particle:      0', b'Particle:      1']\n",
      "Third modif --> [b'Particle:     -3', b'Particle:      0', b'Particle:     -5']\n"
     ]
    }
   ],
   "source": [
    "# Similarly, with an array of strings:\n",
    "nameObject = h5file.root.columns.name\n",
    "print(\"Before modif -->\", nameObject[:])\n",
    "\n",
    "nameObject[0] = b'Particle:   None'\n",
    "print(\"First modif -->\", nameObject[:])\n",
    "\n",
    "nameObject[1:3] = ['Particle:      0', 'Particle:      1']\n",
    "print(\"Second modif -->\", nameObject[:])\n",
    "\n",
    "nameObject[::2] = ['Particle:     -3', 'Particle:     -5']\n",
    "print(\"Third modif -->\", nameObject[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And finally… how to delete rows from a table\n",
    "We’ll finish this tutorial by deleting some rows from the table we have. Suppose that we want to delete the 5th to 9th rows (inclusive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.remove_rows(5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Table.remove_rows()` deletes the rows in the range (start, stop). It returns the number of rows effectively removed.\n",
    "\n",
    "We have reached the end of this first tutorial. Don’t forget to close the file when you finish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    " h5file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
